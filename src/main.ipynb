{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## UDA CHALLENGE\r\n",
    "\r\n",
    "This notebook has been created to answer the below questions:\r\n",
    "\r\n",
    "Using the business.json dataset, and filtering out all businesses that are closed can you calculate:\r\n",
    "\r\n",
    "Q1 - Median and p95 opening time during the week, by postal code, city, and state triplet.\r\n",
    "\r\n",
    "Q2 - Median and p95 closing time during the week, by postal code, city, and state triplet.\r\n",
    "\r\n",
    "Q3 - The number of businesses that are open past 21:00, by city and state pair.\r\n",
    "\r\n",
    "By combining the business.json and review.json dataset, can you calculate:\r\n",
    "\r\n",
    "Q4 - For each postal code, city, and state triplet, the business with the highest number of “cool” review votes that are not open on Sunday."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Though this exercise could have been done in a Python file to ease production. For readability, it has been done in a Jupiter notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LIBRARIES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import os\r\n",
    "\r\n",
    "import utils.mining_data as md \r\n",
    "\r\n",
    "from pyspark.sql import SparkSession\r\n",
    "from pyspark.sql.functions import col"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ACCESS\r\n",
    "\r\n",
    "To access previous local folders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# path to the data folder where downloaded data has been saved\r\n",
    "path_data = md.route(1) + os.sep + \"data\" + os.sep"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## READ DATA\r\n",
    "\r\n",
    "As data can grow exponentially PySpark is used to be able to process larger datasets, (i.e. pandas library wouldn't be able to cope with an extremely large amount of data)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Start a SparkSession\r\n",
    "spark = SparkSession.builder.appName(\"uda_test\").getOrCreate()\r\n",
    "sc = spark.sparkContext"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first question relates to the 'business' data. Therefore, this notebook will start working with this json first"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Read the json file\r\n",
    "df_business = spark.read.json(path_data + \"yelp_academic_dataset_business.json\")\r\n",
    "\r\n",
    "# Quick check the dataframe has been loaded correctly\r\n",
    "df_business.show(3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+--------+--------------------+-------+-------------+---------------+--------------------+-----------+------------+-----+-----+\n",
      "|            address|          attributes|         business_id|          categories|    city|               hours|is_open|     latitude|      longitude|                name|postal_code|review_count|stars|state|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------+--------------------+-------+-------------+---------------+--------------------+-----------+------------+-----+-----+\n",
      "|       921 Pearl St|{null, null, 'bee...|6iYb2HFDywm3zjuRg...|Gastropubs, Food,...| Boulder|{11:0-23:0, 11:0-...|      1|   40.0175444|   -105.2833481| Oskar Blues Taproom|      80302|          86|  4.0|   CO|\n",
      "|7000 NE Airport Way|{null, null, u'be...|tCbdrRPZA0oiIYSmH...|Salad, Soup, Sand...|Portland|{5:0-18:0, 5:0-18...|      1|45.5889058992|-122.5933307507|Flying Elephants ...|      97218|         126|  4.0|   OR|\n",
      "| 4720 Hawthorne Ave|{null, null, null...|bvN78flM8NLprQ1a1...|Antiques, Fashion...|Portland|{11:0-18:0, null,...|      1|45.5119069956|-122.6136928797|      The Reclaimory|      97214|          13|  4.5|   OR|\n",
      "+-------------------+--------------------+--------------------+--------------------+--------+--------------------+-------+-------------+---------------+--------------------+-----------+------------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UNDERSTANDING DATA\r\n",
    "\r\n",
    "Filtering out all businesses that are closed, the first question asks for the median and p95 opening time during the week, by postal code, city, and state triplet. Therefore, the first thing that will be done will be to filter out all closed business. Then opening hours of the week will be extracted, converted to float, and grouped them by postal code, city and state to calculate the median and p95.\r\n",
    "\r\n",
    "\r\n",
    "First, filtering out all businessess that are closed:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Check which column describes if the business is opened or closed\r\n",
    "df_business.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[summary: string, address: string, business_id: string, categories: string, city: string, is_open: string, latitude: string, longitude: string, name: string, postal_code: string, review_count: string, stars: string, state: string]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# The column 'is_open'= 0 or 1 for closed or opened respectively\r\n",
    "df = df_business.filter(\"is_open == 1\")\r\n",
    "\r\n",
    "# Quick check to ensure only opened businesses are kept\r\n",
    "df.select(\"is_open\").head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(is_open=1),\n",
       " Row(is_open=1),\n",
       " Row(is_open=1),\n",
       " Row(is_open=1),\n",
       " Row(is_open=1)]"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For clarity only the relevant business characteristics for this exercise are maintained in the dataframe. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Hours are extracted from the dictionary to show each day of the week per column\r\n",
    "# Some days contain Null values. They can be replaced by zeros but in this case they will be ignored when calculating the median and p95 \r\n",
    "# to avoid misleading results as zeros can also represent midnight\r\n",
    "\r\n",
    "# The days of the week are not in order, however this isn't relevant for the calculations we are going to perform, so they won't be modified\r\n",
    "df = df[\"hours.*\", \"postal_code\", \"city\", \"state\"]\r\n",
    "df.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+---------+---------+----------+----------+----------+-----------+--------------+-----+\n",
      "|    Friday|    Monday| Saturday|   Sunday|  Thursday|   Tuesday| Wednesday|postal_code|          city|state|\n",
      "+----------+----------+---------+---------+----------+----------+----------+-----------+--------------+-----+\n",
      "| 11:0-23:0| 11:0-23:0|11:0-23:0|11:0-23:0| 11:0-23:0| 11:0-23:0| 11:0-23:0|      80302|       Boulder|   CO|\n",
      "|  5:0-18:0|  5:0-18:0| 5:0-18:0| 5:0-18:0|  5:0-18:0|  5:0-17:0|  5:0-18:0|      97218|      Portland|   OR|\n",
      "| 11:0-18:0|      null|11:0-18:0|11:0-18:0| 11:0-18:0|      null|      null|      97214|      Portland|   OR|\n",
      "|      null|      null|     null|     null|      null|      null|      null|      32763|   Orange City|   FL|\n",
      "| 16:0-19:0| 16:0-19:0| 9:0-11:0|     null| 16:0-19:0| 16:0-19:0| 16:0-19:0|      30316|       Atlanta|   GA|\n",
      "| 17:0-21:0| 17:0-21:0|17:0-21:0|17:0-21:0| 17:0-21:0| 17:0-21:0| 17:0-21:0|        V5V|     Vancouver|   BC|\n",
      "| 8:0-17:30|   0:0-0:0|     null|     null| 8:0-17:30| 8:0-17:30| 8:0-17:30|      32804|       Orlando|   FL|\n",
      "|      null|      null| 8:0-14:0| 8:0-14:0|      null|      null|      null|      43206|      Columbus|   OH|\n",
      "|12:15-17:0|12:15-17:0|     null|     null|12:15-17:0|12:15-17:0|12:15-17:0|      78752|        Austin|   TX|\n",
      "|  8:0-20:0|  8:0-20:0| 8:0-20:0| 8:0-20:0|  8:0-20:0|  8:0-20:0|  8:0-20:0|      80302|       Boulder|   CO|\n",
      "|  9:0-18:0| 10:0-15:0| 7:0-16:0|     null|  9:0-18:0|  9:0-18:0|  9:0-18:0|      01960|       Peabody|   MA|\n",
      "| 11:0-22:0| 11:0-21:0|11:0-22:0|     null| 11:0-21:0| 11:0-21:0| 11:0-21:0|      01960|       Peabody|   MA|\n",
      "| 11:0-18:0|      null|11:0-18:0|     null| 11:0-18:0| 11:0-18:0| 11:0-18:0|      32806|       Orlando|   FL|\n",
      "| 8:0-18:30|  8:0-18:0|8:0-18:30| 9:0-17:0|  8:0-18:0|  8:0-18:0|  8:0-18:0|      30083|Stone Mountain|   GA|\n",
      "|  7:0-22:0|   0:0-0:0| 7:0-22:0| 7:0-22:0|  7:0-22:0|  7:0-22:0|  7:0-22:0|      32830|       Orlando|   FL|\n",
      "|  8:0-17:0|  8:0-20:0| 9:0-13:0|     null|  8:0-20:0|  8:0-20:0|  8:0-20:0|      02148|        Malden|   MA|\n",
      "|      null|      null|     null|     null|      null|      null|      null|      32809|   Pine Castle|   FL|\n",
      "| 10:0-16:0|   0:0-0:0|10:0-16:0|10:0-16:0| 10:0-16:0|      null|      null|      97210|      Portland|   OR|\n",
      "|   0:0-0:0|   0:0-0:0|  0:0-0:0|  0:0-0:0|   0:0-0:0|   0:0-0:0|   0:0-0:0|      78752|        Austin|   TX|\n",
      "| 6:30-22:0| 6:30-22:0|6:30-22:0|6:30-20:0| 6:30-22:0| 6:30-22:0| 6:30-22:0|      02215|        Boston|   MA|\n",
      "+----------+----------+---------+---------+----------+----------+----------+-----------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check there aren't any Null values in the columns 'postal_code', 'city' or 'state' as those are the columns that will be used for our analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# These columns don't have any Nulls. Therefore, we can carry on the exercise without any modifications to them\r\n",
    "df.where(col(\"state\").isNull()).show()\r\n",
    "df.where(col(\"city\").isNull()).show()\r\n",
    "df.where(col(\"postal_code\").isNull()).show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "+------+------+--------+------+--------+-------+---------+-----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert hours from string to float format\r\n",
    "\r\n",
    "Business hours are saved as string. They will be converted to float to calculate the median and p95 of all businesses during the week."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Check data format\r\n",
    "df.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- Friday: string (nullable = true)\n",
      " |-- Monday: string (nullable = true)\n",
      " |-- Saturday: string (nullable = true)\n",
      " |-- Sunday: string (nullable = true)\n",
      " |-- Thursday: string (nullable = true)\n",
      " |-- Tuesday: string (nullable = true)\n",
      " |-- Wednesday: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Replace ':' to '.' to be able to convert the data to float\r\n",
    "df = md.change_time(dataframe=df, column_range=df.columns[:7])\r\n",
    "\r\n",
    "# Quick check this operation was done successfully\r\n",
    "df.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+-----------+-----------+-----+\n",
      "|   Friday|   Monday| Saturday|   Sunday| Thursday|  Tuesday|Wednesday|postal_code|       city|state|\n",
      "+---------+---------+---------+---------+---------+---------+---------+-----------+-----------+-----+\n",
      "|11.0-23.0|11.0-23.0|11.0-23.0|11.0-23.0|11.0-23.0|11.0-23.0|11.0-23.0|      80302|    Boulder|   CO|\n",
      "| 5.0-18.0| 5.0-18.0| 5.0-18.0| 5.0-18.0| 5.0-18.0| 5.0-17.0| 5.0-18.0|      97218|   Portland|   OR|\n",
      "|11.0-18.0|     null|11.0-18.0|11.0-18.0|11.0-18.0|     null|     null|      97214|   Portland|   OR|\n",
      "|     null|     null|     null|     null|     null|     null|     null|      32763|Orange City|   FL|\n",
      "|16.0-19.0|16.0-19.0| 9.0-11.0|     null|16.0-19.0|16.0-19.0|16.0-19.0|      30316|    Atlanta|   GA|\n",
      "+---------+---------+---------+---------+---------+---------+---------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Opening and closing hours are split to different columns to be able to calculate the median and p95 at each time.\r\n",
    "# As the first question only requires opening times, closing times won't be printed just yet to avoid confusion. \r\n",
    "# The same function will be used when working with closing times.\r\n",
    "df_open = md.split_hours(df, df.schema.names[:7], time_to_check = \"opening\")\r\n",
    "\r\n",
    "# Check the function worked\r\n",
    "df_open.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|       city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|  11.0|  11.0|    11.0|  11.0|    11.0|   11.0|     11.0|      80302|    Boulder|   CO|\n",
      "|   5.0|   5.0|     5.0|   5.0|     5.0|    5.0|      5.0|      97218|   Portland|   OR|\n",
      "|  11.0|  null|    11.0|  11.0|    11.0|   null|     null|      97214|   Portland|   OR|\n",
      "|  null|  null|    null|  null|    null|   null|     null|      32763|Orange City|   FL|\n",
      "|  16.0|  16.0|     9.0|  null|    16.0|   16.0|     16.0|      30316|    Atlanta|   GA|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As mentioned before Null values are ignored for the purpose of this exercise. It is not recommended to convert them to zeros as these represent 24.00h and can alter results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Converting hours from string to float format\r\n",
    "df_open = md.convert_to_num(df_open.schema.names[:7], df_open, \"float\")\r\n",
    "\r\n",
    "df_open.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- Friday: float (nullable = true)\n",
      " |-- Monday: float (nullable = true)\n",
      " |-- Saturday: float (nullable = true)\n",
      " |-- Sunday: float (nullable = true)\n",
      " |-- Thursday: float (nullable = true)\n",
      " |-- Tuesday: float (nullable = true)\n",
      " |-- Wednesday: float (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1\r\n",
    "\r\n",
    "Median and p95 opening time during the week by postal code, city, and state triplet."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# To keep the results clear the median and p95 will be shown in different dataframes\r\n",
    "\r\n",
    "# Median\r\n",
    "# The median is the value where 50% or the data values fall at or below it. Therefore, it is the same than the 50% percentile. \r\n",
    "# The below function uses the in-build 50% percentile method in pyspark library.\r\n",
    "df1_median = md.calc_percentile(df_open, df_open.schema.names[:7], 0.5, df_open.schema.names[:7], [\"postal_code\", \"city\", \"state\"])\r\n",
    "df1_median.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+\n",
      "|postal_code|            city|state|Fri_p0.5|Mon_p0.5|Sat_p0.5|Sun_p0.5|Thu_p0.5|Tue_p0.5|Wed_p0.5|\n",
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+\n",
      "|      02119|         Roxbury|   MA|     9.0|     7.3|     9.0|     8.0|     8.3|     9.0|     8.3|\n",
      "|      02129|          Boston|   MA|     8.0|     7.0|     8.0|     8.0|     8.0|     8.0|     8.0|\n",
      "|      32830|Lake Buena Vista|   FL|    10.0|     9.0|    10.0|    10.0|    10.0|    10.0|    10.0|\n",
      "|      43140|          London|   OH|     8.0|     7.0|     7.0|     6.0|     8.0|     7.0|     8.0|\n",
      "|      97034|     Lake Oswego|   OR|     9.0|     7.3|     9.3|    10.0|     9.0|     9.0|     9.0|\n",
      "|    V5Z 3A3|       Vancouver|   BC|     9.3|     9.3|     9.3|     9.3|     9.3|     9.3|     9.3|\n",
      "|    V7V 1H8|  West Vancouver|   BC|    10.0|     8.0|    10.0|     9.0|    10.0|     8.0|     8.0|\n",
      "|    V3H 2B2|      Port Moody|   BC|    16.0|    16.0|    12.0|    12.0|    11.3|    11.3|    16.0|\n",
      "|    V5V 4B9|       Vancouver|   BC|    11.3|    11.3|    10.0|    10.0|    11.3|    11.3|    11.3|\n",
      "|    V5Z 3V6|       Vancouver|   BC|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|\n",
      "|    V6E 1V8|       Vancouver|   BC|     7.0|     7.0|     8.0|     8.0|     7.0|     7.0|     7.0|\n",
      "|    V6G 1C9|       Vancouver|   BC|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|\n",
      "|    V7M 2H5| North Vancouver|   BC|    17.3|    17.3|    17.3|    17.3|    17.3|    17.3|    17.3|\n",
      "|    V4C 2S2|           Delta|   BC|    16.0|    null|    16.0|    16.0|    16.0|    16.0|    16.0|\n",
      "|    V5J 1G3|         Burnaby|   BC|    null|    null|    null|    null|    null|    null|    null|\n",
      "|    V7J 2A1| North Vancouver|   BC|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|\n",
      "|    V3B 5E2|       Coquitlam|   BC|    10.0|    14.0|    10.0|    12.0|    10.0|    10.0|    10.0|\n",
      "|    V5K 5A6|       Vancouver|   BC|     9.3|     9.3|    10.0|    10.0|     9.3|     9.3|     9.3|\n",
      "|    V5Y 1J9|       Vancouver|   BC|     9.3|     9.3|    null|    null|     9.3|     9.3|     9.3|\n",
      "|    V6A 0B4|       Vancouver|   BC|    12.0|     9.0|    10.0|    10.0|    12.0|    12.0|    12.0|\n",
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that opening/closing hours are split, all days can be easily grouped to calculate the median and p95 of all days together if required. In this case a new column, being a list of all week-days' hours, could be created and the median and p95 would be calculated to this column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Calculate the median of all days together\r\n",
    "total_median = md.total_percentile(df_open, df_open.schema.names[:7], 0.5, \"Total Median\", [\"postal_code\", \"city\", \"state\"])\r\n",
    "\r\n",
    "total_median.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------+-----+------------+\n",
      "|postal_code|            city|state|Total Median|\n",
      "+-----------+----------------+-----+------------+\n",
      "|      02119|         Roxbury|   MA|         9.0|\n",
      "|      02129|          Boston|   MA|         8.0|\n",
      "|      32830|Lake Buena Vista|   FL|        10.0|\n",
      "|      43140|          London|   OH|         8.0|\n",
      "|      97034|     Lake Oswego|   OR|         9.0|\n",
      "|    V5Z 3A3|       Vancouver|   BC|         9.3|\n",
      "|    V7V 1H8|  West Vancouver|   BC|        10.0|\n",
      "|    V3H 2B2|      Port Moody|   BC|        16.0|\n",
      "|    V5V 4B9|       Vancouver|   BC|        11.3|\n",
      "|    V5Z 3V6|       Vancouver|   BC|        11.0|\n",
      "|    V6E 1V8|       Vancouver|   BC|         8.0|\n",
      "|    V6G 1C9|       Vancouver|   BC|        11.0|\n",
      "|    V7M 2H5| North Vancouver|   BC|        17.3|\n",
      "|    V4C 2S2|           Delta|   BC|        16.0|\n",
      "|    V5J 1G3|         Burnaby|   BC|        null|\n",
      "|    V7J 2A1| North Vancouver|   BC|        11.0|\n",
      "|    V3B 5E2|       Coquitlam|   BC|        12.0|\n",
      "|    V5K 5A6|       Vancouver|   BC|        10.0|\n",
      "|    V5Y 1J9|       Vancouver|   BC|         9.3|\n",
      "|    V6A 0B4|       Vancouver|   BC|        12.0|\n",
      "+-----------+----------------+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# The total median is appended to the previous dataframe which was showing the median per day\r\n",
    "\r\n",
    "df1_median = df1_median.join(total_median, [\"postal_code\", \"city\", \"state\"])\r\n",
    "df1_median.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+------------+\n",
      "|postal_code|            city|state|Fri_p0.5|Mon_p0.5|Sat_p0.5|Sun_p0.5|Thu_p0.5|Tue_p0.5|Wed_p0.5|Total Median|\n",
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+------------+\n",
      "|      02119|         Roxbury|   MA|     9.0|     7.3|     9.0|     8.0|     8.3|     9.0|     8.3|         9.0|\n",
      "|      02129|          Boston|   MA|     8.0|     7.0|     8.0|     8.0|     8.0|     8.0|     8.0|         8.0|\n",
      "|      32830|Lake Buena Vista|   FL|    10.0|     9.0|    10.0|    10.0|    10.0|    10.0|    10.0|        10.0|\n",
      "|      43140|          London|   OH|     8.0|     7.0|     7.0|     6.0|     8.0|     7.0|     8.0|         8.0|\n",
      "|      97034|     Lake Oswego|   OR|     9.0|     7.3|     9.3|    10.0|     9.0|     9.0|     9.0|         9.0|\n",
      "|    V5Z 3A3|       Vancouver|   BC|     9.3|     9.3|     9.3|     9.3|     9.3|     9.3|     9.3|         9.3|\n",
      "|    V7V 1H8|  West Vancouver|   BC|    10.0|     8.0|    10.0|     9.0|    10.0|     8.0|     8.0|        10.0|\n",
      "|    V3H 2B2|      Port Moody|   BC|    16.0|    16.0|    12.0|    12.0|    11.3|    11.3|    16.0|        16.0|\n",
      "|    V5V 4B9|       Vancouver|   BC|    11.3|    11.3|    10.0|    10.0|    11.3|    11.3|    11.3|        11.3|\n",
      "|    V5Z 3V6|       Vancouver|   BC|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|        11.0|\n",
      "|    V6E 1V8|       Vancouver|   BC|     7.0|     7.0|     8.0|     8.0|     7.0|     7.0|     7.0|         8.0|\n",
      "|    V6G 1C9|       Vancouver|   BC|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|        11.0|\n",
      "|    V7M 2H5| North Vancouver|   BC|    17.3|    17.3|    17.3|    17.3|    17.3|    17.3|    17.3|        17.3|\n",
      "|    V4C 2S2|           Delta|   BC|    16.0|    null|    16.0|    16.0|    16.0|    16.0|    16.0|        16.0|\n",
      "|    V5J 1G3|         Burnaby|   BC|    null|    null|    null|    null|    null|    null|    null|        null|\n",
      "|    V7J 2A1| North Vancouver|   BC|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|    11.0|        11.0|\n",
      "|    V3B 5E2|       Coquitlam|   BC|    10.0|    14.0|    10.0|    12.0|    10.0|    10.0|    10.0|        12.0|\n",
      "|    V5K 5A6|       Vancouver|   BC|     9.3|     9.3|    10.0|    10.0|     9.3|     9.3|     9.3|        10.0|\n",
      "|    V5Y 1J9|       Vancouver|   BC|     9.3|     9.3|    null|    null|     9.3|     9.3|     9.3|         9.3|\n",
      "|    V6A 0B4|       Vancouver|   BC|    12.0|     9.0|    10.0|    10.0|    12.0|    12.0|    12.0|        12.0|\n",
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The same procedure is used to calculate the 95% percentile"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# P95\r\n",
    "\r\n",
    "# p95 is calculated per week-day\r\n",
    "df1_p95 = md.calc_percentile(df_open, df_open.schema.names[:7], 0.95, df_open.schema.names[:7], [\"postal_code\", \"city\", \"state\"])\r\n",
    "\r\n",
    "# The total p95 of all days together is calculated\r\n",
    "total_p95 = md.total_percentile(df_open, df_open.schema.names[:7], 0.95, \"Total P95\", [\"postal_code\", \"city\", \"state\"])\r\n",
    "\r\n",
    "# Both answers are combined in one dataframe\r\n",
    "df1_p95 = df1_p95.join(total_p95, [\"postal_code\", \"city\", \"state\"])\r\n",
    "\r\n",
    "df1_p95.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------+-----+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|postal_code|            city|state|Fri_p0.95|Mon_p0.95|Sat_p0.95|Sun_p0.95|Thu_p0.95|Tue_p0.95|Wed_p0.95|Total P95|\n",
      "+-----------+----------------+-----+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|      02119|         Roxbury|   MA|     16.0|     12.0|     13.0|     13.0|     12.0|     16.0|     12.0|     13.0|\n",
      "|      02129|          Boston|   MA|     16.0|     12.0|     12.0|     12.0|     16.0|     16.0|     16.0|     16.0|\n",
      "|      32830|Lake Buena Vista|   FL|     17.0|     15.3|     16.3|     16.3|     17.0|     17.0|     17.0|     16.3|\n",
      "|      43140|          London|   OH|     16.0|     16.0|     16.0|     11.0|     16.0|     16.0|     16.0|     16.0|\n",
      "|      97034|     Lake Oswego|   OR|     16.0|     14.0|     16.0|     16.0|     16.0|     16.0|     16.0|     16.0|\n",
      "|    V5Z 3A3|       Vancouver|   BC|      9.3|      9.3|      9.3|      9.3|      9.3|      9.3|      9.3|      9.3|\n",
      "|    V7V 1H8|  West Vancouver|   BC|     11.0|     11.0|     11.0|     11.0|     11.0|     10.0|     10.0|     11.0|\n",
      "|    V3H 2B2|      Port Moody|   BC|     16.0|     16.0|     16.0|     16.0|     16.0|     16.0|     16.0|     16.0|\n",
      "|    V5V 4B9|       Vancouver|   BC|     11.3|     11.3|     10.0|     10.0|     11.3|     11.3|     11.3|     11.3|\n",
      "|    V5Z 3V6|       Vancouver|   BC|     11.0|     11.0|     11.0|     11.0|     11.0|     11.0|     11.0|     11.0|\n",
      "|    V6E 1V8|       Vancouver|   BC|     17.3|     17.3|     17.3|     12.0|     17.3|     17.3|     17.3|     17.3|\n",
      "|    V6G 1C9|       Vancouver|   BC|     18.0|     16.3|     16.3|     16.3|     16.3|     17.0|     17.0|     16.3|\n",
      "|    V7M 2H5| North Vancouver|   BC|     17.3|     17.3|     17.3|     17.3|     17.3|     17.3|     17.3|     17.3|\n",
      "|    V4C 2S2|           Delta|   BC|     16.0|     null|     16.0|     16.0|     16.0|     16.0|     16.0|     16.0|\n",
      "|    V5J 1G3|         Burnaby|   BC|     null|     null|     null|     null|     null|     null|     null|     null|\n",
      "|    V7J 2A1| North Vancouver|   BC|     11.0|     11.0|     11.0|     11.0|     11.0|     11.0|     11.0|     11.0|\n",
      "|    V3B 5E2|       Coquitlam|   BC|     12.0|     14.0|     12.0|     12.0|     14.0|     14.0|     14.0|     14.0|\n",
      "|    V5K 5A6|       Vancouver|   BC|     17.3|      9.3|     17.3|     10.0|     17.3|     17.3|     17.3|     17.3|\n",
      "|    V5Y 1J9|       Vancouver|   BC|      9.3|      9.3|     null|     null|      9.3|      9.3|      9.3|      9.3|\n",
      "|    V6A 0B4|       Vancouver|   BC|     17.0|     12.0|     12.0|     12.0|     17.0|     17.0|     17.0|     17.0|\n",
      "+-----------+----------------+-----+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\r\n",
    "\r\n",
    "Median and p95 closing time during the week, by postal code, city, and state triplet."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# The second question is very similar to the first one, so it is not necessary to start the same process from the beginning\r\n",
    "# Closing hours are saved in a dataframe. In this case opening hours are disregarded\r\n",
    "df_close = md.split_hours(df, df.schema.names[:7], time_to_check = \"closing\")\r\n",
    "\r\n",
    "# Converting hours from string to float format\r\n",
    "df_close = md.convert_to_num(df_close.schema.names[:7], df_close, \"float\")\r\n",
    "\r\n",
    "df_close.show(5)\r\n",
    "\r\n",
    "# Quick check to ensure the column 'hours' has been converted to float successfuly\r\n",
    "df_close.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|       city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|  23.0|  23.0|    23.0|  23.0|    23.0|   23.0|     23.0|      80302|    Boulder|   CO|\n",
      "|  18.0|  18.0|    18.0|  18.0|    18.0|   17.0|     18.0|      97218|   Portland|   OR|\n",
      "|  18.0|  null|    18.0|  18.0|    18.0|   null|     null|      97214|   Portland|   OR|\n",
      "|  null|  null|    null|  null|    null|   null|     null|      32763|Orange City|   FL|\n",
      "|  19.0|  19.0|    11.0|  null|    19.0|   19.0|     19.0|      30316|    Atlanta|   GA|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Friday: float (nullable = true)\n",
      " |-- Monday: float (nullable = true)\n",
      " |-- Saturday: float (nullable = true)\n",
      " |-- Sunday: float (nullable = true)\n",
      " |-- Thursday: float (nullable = true)\n",
      " |-- Tuesday: float (nullable = true)\n",
      " |-- Wednesday: float (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# To keep the results clear the median and p95 will be calculated in different dataframes\r\n",
    "\r\n",
    "# Similar to before, the same procedure is used to calculate the median for the closing hours \r\n",
    "df2_median = md.calc_percentile(df_close, df_close.schema.names[:7], 0.5, df_close.schema.names[:7], [\"postal_code\", \"city\", \"state\"])\r\n",
    "total_median_2 = md.total_percentile(df_close, df_close.schema.names[:7], 0.5, \"Total Median\", [\"postal_code\", \"city\", \"state\"])\r\n",
    "df2_median = df2_median.join(total_median_2, [\"postal_code\", \"city\", \"state\"])\r\n",
    "\r\n",
    "df2_median.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+------------+\n",
      "|postal_code|            city|state|Fri_p0.5|Mon_p0.5|Sat_p0.5|Sun_p0.5|Thu_p0.5|Tue_p0.5|Wed_p0.5|Total Median|\n",
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+------------+\n",
      "|      02119|         Roxbury|   MA|    18.0|    17.0|    17.0|    21.3|    19.0|    18.0|    18.0|        18.0|\n",
      "|      02129|          Boston|   MA|    18.0|    17.0|    17.0|    17.0|    18.0|    18.0|    18.0|        17.3|\n",
      "|      32830|Lake Buena Vista|   FL|    21.0|    19.0|    21.0|    21.0|    21.0|    21.0|    21.0|        21.0|\n",
      "|      43140|          London|   OH|    20.0|    20.0|    20.0|     0.0|    20.0|    19.0|    20.0|        20.0|\n",
      "|      97034|     Lake Oswego|   OR|    18.0|    17.0|    18.0|    18.0|    18.0|    18.0|    18.0|        18.0|\n",
      "|    V5Z 3A3|       Vancouver|   BC|    23.0|    23.0|    23.0|    21.0|    23.0|    23.0|    23.0|        23.0|\n",
      "|    V7V 1H8|  West Vancouver|   BC|    18.0|    17.0|    18.0|    16.0|    18.0|    17.0|    17.0|        17.0|\n",
      "|    V3H 2B2|      Port Moody|   BC|    20.3|    20.0|    20.3|     0.0|     0.0|     0.0|    20.0|        20.0|\n",
      "|    V5V 4B9|       Vancouver|   BC|     1.0|     0.0|     1.0|     0.0|     0.0|     0.0|     0.0|         0.0|\n",
      "|    V5Z 3V6|       Vancouver|   BC|    22.0|    22.0|    22.0|    21.0|    22.0|    22.0|    22.0|        22.0|\n",
      "|    V6E 1V8|       Vancouver|   BC|    19.0|    18.0|    18.0|    17.0|    19.0|    18.0|    18.0|        19.0|\n",
      "|    V6G 1C9|       Vancouver|   BC|    21.0|    21.0|    21.0|    21.0|    21.0|    21.0|    21.0|        21.0|\n",
      "|    V7M 2H5| North Vancouver|   BC|    22.0|    22.0|    22.0|    21.3|    22.0|    22.0|    22.0|        22.0|\n",
      "|    V4C 2S2|           Delta|   BC|    22.0|    null|    22.0|    21.0|    21.0|    21.0|    21.0|        21.0|\n",
      "|    V5J 1G3|         Burnaby|   BC|    null|    null|    null|    null|    null|    null|    null|        null|\n",
      "|    V7J 2A1| North Vancouver|   BC|     1.0|     0.0|     1.0|     0.0|     0.0|     0.0|     0.0|         0.0|\n",
      "|    V3B 5E2|       Coquitlam|   BC|    18.0|    22.0|    17.0|    17.0|    18.0|    18.0|    18.0|        21.0|\n",
      "|    V5K 5A6|       Vancouver|   BC|    20.0|    21.0|    19.0|    19.0|    20.0|    20.0|    20.0|        20.0|\n",
      "|    V5Y 1J9|       Vancouver|   BC|    18.0|    17.3|    null|    null|    17.3|    17.3|    17.3|        17.3|\n",
      "|    V6A 0B4|       Vancouver|   BC|     2.0|    21.0|     2.3|     1.0|    21.0|    21.0|    21.0|        21.0|\n",
      "+-----------+----------------+-----+--------+--------+--------+--------+--------+--------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# The same procedure is used to calculate the 95% percentile\r\n",
    "df2_p95 = md.calc_percentile(df_close, df_close.schema.names[:7], 0.95, df_close.schema.names[:7], [\"postal_code\", \"city\", \"state\"])\r\n",
    "total_p95_2 = md.total_percentile(df_close, df_close.schema.names[:7], 0.95, \"Total P95\", [\"postal_code\", \"city\", \"state\"])\r\n",
    "df2_p95 = df2_p95.join(total_p95_2, [\"postal_code\", \"city\", \"state\"])\r\n",
    "\r\n",
    "df2_p95.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------------+-----+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|postal_code|            city|state|Fri_p0.95|Mon_p0.95|Sat_p0.95|Sun_p0.95|Thu_p0.95|Tue_p0.95|Wed_p0.95|Total P95|\n",
      "+-----------+----------------+-----+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|      02119|         Roxbury|   MA|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|\n",
      "|      02129|          Boston|   MA|     22.0|     22.0|     22.0|     23.0|     22.0|     22.0|     22.0|     22.0|\n",
      "|      32830|Lake Buena Vista|   FL|     23.3|     23.0|     23.3|     23.0|     23.0|     23.0|     23.0|     23.0|\n",
      "|      43140|          London|   OH|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|\n",
      "|      97034|     Lake Oswego|   OR|     22.0|     21.3|     22.0|     22.0|     21.0|     22.0|     22.0|     22.0|\n",
      "|    V5Z 3A3|       Vancouver|   BC|     23.0|     23.0|     23.0|     21.0|     23.0|     23.0|     23.0|     23.0|\n",
      "|    V7V 1H8|  West Vancouver|   BC|     20.0|     20.0|     20.0|     20.0|     20.0|     18.0|     18.0|     20.0|\n",
      "|    V3H 2B2|      Port Moody|   BC|     23.0|     22.3|     23.0|     20.0|     22.3|     22.3|     22.3|     23.0|\n",
      "|    V5V 4B9|       Vancouver|   BC|      1.0|      0.0|      1.0|      0.0|      0.0|      0.0|      0.0|      1.0|\n",
      "|    V5Z 3V6|       Vancouver|   BC|     22.0|     22.0|     22.0|     21.0|     22.0|     22.0|     22.0|     22.0|\n",
      "|    V6E 1V8|       Vancouver|   BC|     22.0|     22.0|     22.0|     22.0|     22.0|     22.0|     22.0|     22.0|\n",
      "|    V6G 1C9|       Vancouver|   BC|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|     23.0|\n",
      "|    V7M 2H5| North Vancouver|   BC|     22.0|     22.0|     22.0|     21.3|     22.0|     22.0|     22.0|     22.0|\n",
      "|    V4C 2S2|           Delta|   BC|     22.0|     null|     22.0|     21.0|     21.0|     21.0|     21.0|     22.0|\n",
      "|    V5J 1G3|         Burnaby|   BC|     null|     null|     null|     null|     null|     null|     null|     null|\n",
      "|    V7J 2A1| North Vancouver|   BC|      1.0|      0.0|      1.0|      0.0|      0.0|      0.0|      0.0|      1.0|\n",
      "|    V3B 5E2|       Coquitlam|   BC|     23.0|     22.0|     23.0|     21.0|     23.0|     22.0|     22.0|     23.0|\n",
      "|    V5K 5A6|       Vancouver|   BC|     21.0|     21.0|     20.0|     19.0|     21.0|     21.0|     21.0|     21.0|\n",
      "|    V5Y 1J9|       Vancouver|   BC|     18.0|     17.3|     null|     null|     17.3|     17.3|     17.3|     18.0|\n",
      "|    V6A 0B4|       Vancouver|   BC|     21.0|     23.0|     21.0|     21.0|     23.0|     23.0|     23.0|     23.0|\n",
      "+-----------+----------------+-----+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3\r\n",
    "\r\n",
    "The number of businesses that are open past 21:00, by city and state pair.\r\n",
    "\r\n",
    "As we have already worked with the 'business' data, we already have a dataframe showing businesses' timetable as float. It is now only required to keep the businesses that are open past 21.00 and grouped them by city and state."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# The previous dataframe 'df_close' already shows the closing information of each business in float format\r\n",
    "# As before Null values are ignored to avoid misleading results. It is not recommended to convert them to zeros as this represents 24.00h\r\n",
    "df_close.show(5)\r\n",
    "df_close.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|       city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|  23.0|  23.0|    23.0|  23.0|    23.0|   23.0|     23.0|      80302|    Boulder|   CO|\n",
      "|  18.0|  18.0|    18.0|  18.0|    18.0|   17.0|     18.0|      97218|   Portland|   OR|\n",
      "|  18.0|  null|    18.0|  18.0|    18.0|   null|     null|      97214|   Portland|   OR|\n",
      "|  null|  null|    null|  null|    null|   null|     null|      32763|Orange City|   FL|\n",
      "|  19.0|  19.0|    11.0|  null|    19.0|   19.0|     19.0|      30316|    Atlanta|   GA|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Friday: float (nullable = true)\n",
      " |-- Monday: float (nullable = true)\n",
      " |-- Saturday: float (nullable = true)\n",
      " |-- Sunday: float (nullable = true)\n",
      " |-- Thursday: float (nullable = true)\n",
      " |-- Tuesday: float (nullable = true)\n",
      " |-- Wednesday: float (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hours can be misleading, when comparing number 21.00 > 3.00 but when talking about hours 21.00pm < 3.00am. Therefore, to avoid any mistakes a two-parts check will be done. \r\n",
    "\r\n",
    "First, if the time is past midnight (0.00) it will automatically be considered as past 21.00h. If the hour is before midnight it will be compared in a one by one basis to 21.00h.\r\n",
    "\r\n",
    "For clarification, if a business is opened past 21.00 one day per week it will be already considered. It won't be required for all days to be opened past 21.00."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Obtain businesses opened between midnight and 10.00am \r\n",
    "\r\n",
    "# When reviewing results some days seem to be open before 21.00. \r\n",
    "# This is becuase only one day per week needs to be opened past 21.00 to consider the business as acceptable answer to this question. \r\n",
    "week = df_close.schema.names[:7]\r\n",
    "df_past_midnight = md.filtering_hours(df_close, week)\r\n",
    "\r\n",
    "# Quick check hours are past midnight, at least one day per week\r\n",
    "df_past_midnight.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|       city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "|   3.0|   3.0|     3.0|   0.0|     3.0|    3.0|      3.0|      30309|    Atlanta|   GA|\n",
      "|   2.0|   0.0|     2.0|   0.0|     0.0|    0.0|      0.0|      80301|    Boulder|   CO|\n",
      "|   1.0|   1.0|     1.0|   1.0|     1.0|    1.0|      1.0|      78729|     Austin|   TX|\n",
      "|  17.3|  null|     5.3|  null|    17.3|   17.3|     17.3|      32789|Winter Park|   FL|\n",
      "|   1.0|   1.0|     1.0|   1.0|     1.0|    1.0|      1.0|      01803| Burlington|   MA|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Obtain businesses opened past 21.00\r\n",
    "df_past_nine = md.filtering_hours(df_close, week, hours= [21.00, 23.59])\r\n",
    "\r\n",
    "# Quick check hours are past 21h, at least one day per week\r\n",
    "df_past_nine.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+--------+------+--------+-------+---------+-----------+--------+-----+\n",
      "|Friday|Monday|Saturday|Sunday|Thursday|Tuesday|Wednesday|postal_code|    city|state|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+--------+-----+\n",
      "|  23.0|  23.0|    23.0|  23.0|    23.0|   23.0|     23.0|      80302| Boulder|   CO|\n",
      "|  22.0|  21.0|    22.0|  null|    21.0|   21.0|     21.0|      01960| Peabody|   MA|\n",
      "|  22.0|   0.0|    22.0|  22.0|    22.0|   22.0|     22.0|      32830| Orlando|   FL|\n",
      "|  22.0|  22.0|    22.0|  20.0|    22.0|   22.0|     22.0|      02215|  Boston|   MA|\n",
      "|   0.0|  23.0|     0.0|  23.0|    23.0|   23.0|     23.0|      97230|Portland|   OR|\n",
      "+------+------+--------+------+--------+-------+---------+-----------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Join together both dataframes\r\n",
    "df_past_nine = df_past_nine.union(df_past_midnight)\r\n",
    "\r\n",
    "# Grouping the combined dataframe by 'city' and 'state' as requested\r\n",
    "df_past_nine = df_past_nine.groupBy(\"city\", \"state\").count()\r\n",
    "\r\n",
    "df_past_nine.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------+-----+-----+\n",
      "|           city|state|count|\n",
      "+---------------+-----+-----+\n",
      "|     Harrisburg|   OH|    1|\n",
      "|      Blacklick|   OH|    8|\n",
      "|      Lake City|   GA|    6|\n",
      "|  North Reading|   MA|   18|\n",
      "|        Deltona|   FL|   39|\n",
      "|        Hanover|   MA|    1|\n",
      "|   Portland, OR|   OR|    1|\n",
      "|    Casselberry|   FL|   59|\n",
      "|   West Roxbury|   MA|   31|\n",
      "|          COCOA|   FL|    1|\n",
      "|  ChampionsGate|   FL|    1|\n",
      "|       St Cloud|   FL|    4|\n",
      "|  Boston-Fenway|   MA|    2|\n",
      "|        Medford|   MA|  109|\n",
      "|          Brice|   OH|    1|\n",
      "|       Superior|   CO|    9|\n",
      "|      Vancouver|  ABE|    1|\n",
      "|North Vancouver|   BC|  166|\n",
      "|      Whitehall|   OH|   17|\n",
      "|           Hull|   MA|   15|\n",
      "+---------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PART II\r\n",
    "## Question 4\r\n",
    "\r\n",
    "By combining the business.json and review.json dataset, can you calculate:\r\n",
    "\r\n",
    "For each postal code, city, and state triplet, the business with the highest number of “cool” review votes that are not open on Sunday.\r\n",
    "\r\n",
    "Now a new json file will need to be loaded and manipulated. The column 'cool' review will need to be converted to int format before combining the dataframes, to then be able to rank businesses based on this column. To avoid a combined dataframe with a lot of irrelevant columns only the required ones will be kept. Only businesses not open on Sunday will be ranked so this column will be maintained and opening/closing hours split to compare these times. Only then the dataframe will be grouped by postal code, city and state to provide the businesses with the higher number of 'cool' votes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# business.json has already been loaded to this notebook. Now we need to read the review.json file\r\n",
    "df_review = spark.read.json(path_data + \"yelp_academic_dataset_review.json\")\r\n",
    "\r\n",
    "# Quick check the file has been loaded correctly\r\n",
    "df_review.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|buF9druCkbuXLX526...|   1|2014-10-11 03:34:02|    1|lWC-xP3rd6obsecCY...|  4.0|Apparently Prides...|     3|ak0TdVmGKo4pwqdJS...|\n",
      "|RA4V8pr014UyUbDvI...|   0|2015-07-03 20:38:25|    0|8bFej1QE5LXp4O05q...|  4.0|This store is pre...|     1|YoVfDbnISlW0f7abN...|\n",
      "|_sS2LBIGNT5NQb6PD...|   0|2013-05-28 20:38:06|    0|NDhkzczKjLshODbqD...|  5.0|I called WVM on t...|     0|eC5evKn1TWDyHCyQA...|\n",
      "|0AzLzHfOJgL7ROwhd...|   1|2010-01-08 02:29:15|    1|T5fAqjjFooT4V0OeZ...|  2.0|I've stayed at ma...|     1|SFQ1jcnGguO0LYWnb...|\n",
      "|8zehGz9jnxPqXtOc7...|   0|2011-07-28 18:05:01|    0|sjm_uUcQVxab_EeLC...|  4.0|The food is alway...|     0|0kA0PAJ8QFMeveQWH...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UNDERSTANDING DATA OF 'REVIEW' DATAFRAME"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df_review.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[summary: string, business_id: string, cool: string, date: string, funny: string, review_id: string, stars: string, text: string, useful: string, user_id: string]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert 'cool' votes from string to integer format\r\n",
    "\r\n",
    "The column 'cool' will need to be converted to int format to be able to order reviews by the number of votes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Converting 'cool' from string to int format\r\n",
    "df_review = md.convert_to_num(df_review.schema.names[1:2], df_review, \"int\")\r\n",
    "\r\n",
    "df_review.printSchema()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For clarity only the relevant characteristics for this exercise are maintained in both dataframes prior to their join. \r\n",
    "\r\n",
    "Filtering out info in 'review' dataframe:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Only the columns 'business_id' (only common column with 'business' dataframe, required to join them) and 'cool' will be maintained\r\n",
    "df_review = df_review.select(col(\"business_id\"), col(\"cool\"))\r\n",
    "\r\n",
    "df_review.show(3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+----+\n",
      "|         business_id|cool|\n",
      "+--------------------+----+\n",
      "|buF9druCkbuXLX526...|   1|\n",
      "|RA4V8pr014UyUbDvI...|   0|\n",
      "|_sS2LBIGNT5NQb6PD...|   0|\n",
      "+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UNDERSTANDING DATA OF 'BUSINESS' DATAFRAME\r\n",
    "\r\n",
    "Filtering out info in 'business' dataframe:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# This dataframe has already been loaded to this notebook. Double check columns format for new question.\r\n",
    "print(df_business.describe())\r\n",
    "\r\n",
    "df_business.select(\"hours.*\").describe()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataFrame[summary: string, address: string, business_id: string, categories: string, city: string, is_open: string, latitude: string, longitude: string, name: string, postal_code: string, review_count: string, stars: string, state: string]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Friday: string, Monday: string, Saturday: string, Sunday: string, Thursday: string, Tuesday: string, Wednesday: string]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Based on the question the required columns are 'business_id' (common column with the other dataframe that will be used to join them),\r\n",
    "# 'name' (name of businesses), 'postal_code', 'state', 'city' (columns to group by the final dataframe),'hours' (to check which Sundays are closed).\r\n",
    "# All business, permanently opened or closed will be considered. Therefore, the column 'is_open' won't be used to filter any information. \r\n",
    "\r\n",
    "df_b = df_business.select(col(\"business_id\"), col(\"name\"), col(\"postal_code\"), col(\"state\"), col(\"city\"), col(\"hours.*\"))\r\n",
    "\r\n",
    "# Check which position the column 'Sunday' is located in the dataframe\r\n",
    "df_b.schema.names[8:9]\r\n",
    "\r\n",
    "# It is understood that null values don't represent when a business is closed, but that no information was available from that business\r\n",
    "# Therefore, a business is closed on Sunday when their opening and closing hours are the same on that day\r\n",
    "# Reusing the function 'split_hours' it is possible to separate this info in different columns to ease their comparison.\r\n",
    "sun_open = md.split_hours(df_b, df_b.schema.names[8:9], \"opening\").withColumnRenamed(\"Sunday\",\"Sun_opening\")\r\n",
    "sun_close = md.split_hours(df_b, df_b.schema.names[8:9], \"closing\").withColumnRenamed(\"Sunday\",\"Sun_closing\")\r\n",
    "\r\n",
    "# Join dataframes with opening and closing hours\r\n",
    "df4 = sun_open.join(sun_close, [\"business_id\", \"name\", \"postal_code\", \"state\", \"city\"])\\\r\n",
    "                                .drop(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")\r\n",
    "\r\n",
    "df4.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+-----------+-----+--------+-----------+-----------+\n",
      "|         business_id|                name|postal_code|state|    city|Sun_opening|Sun_closing|\n",
      "+--------------------+--------------------+-----------+-----+--------+-----------+-----------+\n",
      "|-1rvXk4zbX3I6ddMC...|     ZenCha Tea Cafe|      43209|   OH|  Bexley|       10:0|       17:0|\n",
      "|-56y4ePrMKCZbi059...|Cosmopolitan Rest...|      30067|   GA|Marietta|       11:0|      23:30|\n",
      "|-BgWU01VUnurXHlFo...|Charles Barber & ...|      30084|   GA|  Tucker|       null|       null|\n",
      "|-DzPWvc2PRDtIPa-2...|   Meg B White Salon|      30324|   GA| Atlanta|       null|       null|\n",
      "|-N5w3E16qNruBDGd0...|Green's Grille an...|      01801|   MA|  Woburn|        8:0|       13:0|\n",
      "+--------------------+--------------------+-----------+-----+--------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Dataframe containing only businesses that are not open on Sunday\r\n",
    "df4 = df4.filter(df4[\"Sun_opening\"] == df4[\"Sun_closing\"])\r\n",
    "\r\n",
    "# Quick check this info is correct in the new dataframe\r\n",
    "df4.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+-----------+-----+----------+-----------+-----------+\n",
      "|         business_id|                name|postal_code|state|      city|Sun_opening|Sun_closing|\n",
      "+--------------------+--------------------+-----------+-----+----------+-----------+-----------+\n",
      "|-NEVig2nUPOxHjAkR...|   Remediation Group|      30318|   GA|   Atlanta|        0:0|        0:0|\n",
      "|0GEgDlxdQqMngSEjy...|Urban Express Cha...|      43219|   OH|  Columbus|        0:0|        0:0|\n",
      "|0aJBoc-8eIUH0ysDE...|       Trial Pro, PA|      32801|   FL|   Orlando|        0:0|        0:0|\n",
      "|0jlUpkdXg3LCE44UK...| Portland City Grill|      97204|   OR|  Portland|        0:0|        0:0|\n",
      "|1l_FrJJkI22OMgL9L...|The Two Brothers ...|      02145|   MA|Somerville|        0:0|        0:0|\n",
      "+--------------------+--------------------+-----------+-----+----------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Joining both dataframes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "df4 = df4.join(df_review, on=\"business_id\")\r\n",
    "\r\n",
    "df4.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+-----------+-----------+-----+-------+-----------+-----------+----+\n",
      "|         business_id|       name|postal_code|state|   city|Sun_opening|Sun_closing|cool|\n",
      "+--------------------+-----------+-----------+-----+-------+-----------+-----------+----+\n",
      "|3_vvDzgMFfLEMo8P9...|Ashley Fuel|      01915|   MA|Beverly|        0:0|        0:0|   0|\n",
      "|3_vvDzgMFfLEMo8P9...|Ashley Fuel|      01915|   MA|Beverly|        0:0|        0:0|   0|\n",
      "|3_vvDzgMFfLEMo8P9...|Ashley Fuel|      01915|   MA|Beverly|        0:0|        0:0|   0|\n",
      "|3_vvDzgMFfLEMo8P9...|Ashley Fuel|      01915|   MA|Beverly|        0:0|        0:0|   0|\n",
      "|3_vvDzgMFfLEMo8P9...|Ashley Fuel|      01915|   MA|Beverly|        0:0|        0:0|   0|\n",
      "+--------------------+-----------+-----------+-----+-------+-----------+-----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grouping businesses by postal code, state and city and organising the results based on the highest number of “cool” review votes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Group the dataframe and calculate the max 'cool' votes\r\n",
    "df_cool = df4.groupBy(\"postal_code\", \"city\", \"state\", \"name\").agg({\"cool\": \"max\"})\r\n",
    "\r\n",
    "# Order the dataframe by the highest number of 'cool' reviews\r\n",
    "df_cool = df_cool.sort(df_cool[\"max(cool)\"].desc()) \r\n",
    "\r\n",
    "df_cool.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+-----------+-----+--------------------+---------+\n",
      "|postal_code|       city|state|                name|max(cool)|\n",
      "+-----------+-----------+-----+--------------------+---------+\n",
      "|      02111|     Boston|   MA|The Ritz-Carlton,...|      297|\n",
      "|      01923|    Danvers|   MA|Residence Inn Bos...|      137|\n",
      "|      32819|    Orlando|   FL|Hyatt Regency Orl...|      128|\n",
      "|      32830|    Orlando|   FL|Club Wyndham Bonn...|      123|\n",
      "|      01742|    Concord|   MA|Residence Inn Bos...|      119|\n",
      "|      32821|    Orlando|   FL|Wyndham Grand Orl...|      114|\n",
      "|      02045|       Hull|   MA|The Beacon Luxury...|      112|\n",
      "|      97202|   Portland|   OR|Original Hotcake ...|      106|\n",
      "|      32771|    Sanford|   FL|Comfort Inn & Sui...|      105|\n",
      "|      97204|   Portland|   OR| Portland City Grill|      100|\n",
      "|      32763|Orange City|   FL|Quality Inn near ...|      100|\n",
      "|    V7B 0A4|   Richmond|   BC|Vancouver Interna...|       98|\n",
      "|      78758|     Austin|   TX| Archer Hotel Austin|       96|\n",
      "|      02128|     Boston|   MA|   American Airlines|       94|\n",
      "|      32806|    Orlando|   FL|        Bao's Castle|       94|\n",
      "|      97217|   Portland|   OR|Red Lion Hotel on...|       93|\n",
      "|      32819|    Orlando|   FL|Embassy Suites by...|       92|\n",
      "|      32809|    Orlando|   FL|Sugar Daddy Baker...|       91|\n",
      "|      30320|    Atlanta|   GA|Hartsfield-Jackso...|       89|\n",
      "|      97218|   Portland|   OR|Portland Internat...|       88|\n",
      "+-----------+-----------+-----+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OUTPUT\r\n",
    "\r\n",
    "All produced dataframes will be saved in the folder 'reports' so answers to all questions will be easily accesible."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# When saving dataframes as CSV files Pyspark saves them as a set of CSVs instead of a single file. \r\n",
    "# Therefore, to avoid having to concatenate them again the dataframe is converted to CSV file using Pandas, \r\n",
    "# (though it takes more time to do this operation).\r\n",
    "\r\n",
    "save_path = md.route(1) + os.sep + \"reports\" + os.sep \r\n",
    "\r\n",
    "# Question 1: Median and p95 opening time during the week, by postal code, city, and state triplet.\r\n",
    "md.df_to_csv(df1_median, save_path, \"q1_median_opening\")\r\n",
    "md.df_to_csv(df1_p95, save_path, \"q1_p95_opening\")\r\n",
    "\r\n",
    "# Question 2: Median and p95 closing time during the week, by postal code, city, and state triplet.\r\n",
    "md.df_to_csv(df2_median, save_path, \"q2_median_closing\")\r\n",
    "md.df_to_csv(df2_p95, save_path, \"q2_p95_closing\")\r\n",
    "\r\n",
    "# Question 3: The number of businesses that are open past 21:00, by city and state pair.\r\n",
    "md.df_to_csv(df_past_nine, save_path, \"q3_open_late\")\r\n",
    "\r\n",
    "# Question 4: For each postal code, city, and state triplet, the business with the highest number of “cool” review votes that are not open on Sunday.\r\n",
    "md.df_to_csv(df_cool, save_path, \"q4_cool_votes\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same operation is done again but this time files will be saved as json\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# To save the results of each question in one Avro file per question, \r\n",
    "# the dataframe showing the median and p95 of question 1 and 2 will be combined in one before converting those to json.\r\n",
    "df_q1 = df1_median.join(df1_p95, [\"postal_code\", \"city\", \"state\"])\r\n",
    "df_q2 = df2_median.join(df2_p95, [\"postal_code\", \"city\", \"state\"])\r\n",
    "\r\n",
    "# Question 1: Median and p95 opening time during the week, by postal code, city, and state triplet.\r\n",
    "md.df_to_json(df_q1, save_path, \"q1_opening\")\r\n",
    "\r\n",
    "# Question 2: Median and p95 closing time during the week, by postal code, city, and state triplet.\r\n",
    "md.df_to_json(df_q2, save_path, \"q2_closing\")\r\n",
    "\r\n",
    "# Question 3: The number of businesses that are open past 21:00, by city and state pair.\r\n",
    "md.df_to_json(df_past_nine, save_path, \"q3_open_late\")\r\n",
    "\r\n",
    "# Question 4: For each postal code, city, and state triplet, the business with the highest number of “cool” review votes that are not open on Sunday.\r\n",
    "md.df_to_json(df_cool, save_path, \"q4_cool_votes\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}